{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malleshcr7/AI-ML-Projects/blob/main/Face_recognition_systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real-Time Face Recognition System for Google Colab\n"
      ],
      "metadata": {
        "id": "6J39FBpZnBby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required packages\n",
        "Run this cell once at the start to install libraries needed for face recognition and image handling.\n"
      ],
      "metadata": {
        "id": "WD5HQOG-mz-m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPh3J7111rxM"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install opencv-python cmake dlib face_recognition\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import time\n",
        "\n",
        "print(\"All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Global Variables\n",
        "\n"
      ],
      "metadata": {
        "id": "OXqQ2t11myLY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGbzz0cC14NV",
        "outputId": "d70dd17e-4628-4eb9-a251-e1b51022915c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global variables initialized!\n"
          ]
        }
      ],
      "source": [
        "# Initialize global variables at the start\n",
        "known_face_encodings = []\n",
        "known_face_names = []\n",
        "\n",
        "print(\"Global variables initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Simple Face Detection Function"
      ],
      "metadata": {
        "id": "NgtUwzCNu7cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_faces_simple(image_path):\n",
        "    \"\"\"Simple face detection using Haar Cascade\"\"\"\n",
        "    try:\n",
        "        # Read image\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            print(f\"Error: Could not load image {image_path}\")\n",
        "            return None\n",
        "\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Load face cascade\n",
        "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "        # Detect faces\n",
        "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "        # Draw rectangles around faces\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            cv2.putText(img, \"Face\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "        print(f\"Detected {len(faces)} face(s)\")\n",
        "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in face detection: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test the function\n",
        "print(\"Testing face detection...\")\n",
        "print(\"Upload an image for face detection:\")\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "for filename in uploaded_files.keys():\n",
        "    result = detect_faces_simple(filename)\n",
        "    if result is not None:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.imshow(result)\n",
        "        plt.title(f\"Face Detection: {filename}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "kD321FnAirnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Webcam Photo Capture"
      ],
      "metadata": {
        "id": "GWtHVM9AvAhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    \"\"\"Take a photo using webcam\"\"\"\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Wait for Capture to be clicked.\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "    # Get photo data\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    # Decode base64 image\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    # Save image\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "\n",
        "    return filename\n",
        "\n",
        "def capture_and_detect_faces():\n",
        "    \"\"\"Capture photos and detect faces\"\"\"\n",
        "    print(\"=== WEBCAM FACE DETECTION ===\")\n",
        "    print(\"You will be prompted to take 3 photos.\")\n",
        "    print(\"Click the 'Capture' button when ready for each photo.\")\n",
        "\n",
        "    for i in range(3):\n",
        "        print(f\"\\n Ready for photo {i+1}/3...\")\n",
        "        filename = f'webcam_photo_{i}.jpg'\n",
        "\n",
        "        try:\n",
        "            # Take photo\n",
        "            photo_path = take_photo(filename)\n",
        "            print(\" Photo captured successfully!\")\n",
        "\n",
        "            # Detect faces in the photo\n",
        "            result_image = detect_faces_simple(photo_path)\n",
        "\n",
        "            if result_image is not None:\n",
        "                # Display results\n",
        "                plt.figure(figsize=(10, 8))\n",
        "                plt.imshow(result_image)\n",
        "                plt.title(f\"Webcam Photo {i+1} - Face Detection\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\" No faces detected or error processing image\")\n",
        "\n",
        "            # Wait between photos (except after the last one)\n",
        "            if i < 2:\n",
        "                print(\" Waiting 3 seconds for next photo...\")\n",
        "                time.sleep(3)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Error capturing photo {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "# Run webcam face detection\n",
        "capture_and_detect_faces()"
      ],
      "metadata": {
        "id": "4YsLgbMbisae"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Advanced Multi-Method Face Detection"
      ],
      "metadata": {
        "id": "LDOWeqdgvN6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_face_detection_methods(image_path):\n",
        "    \"\"\"Compare different face detection methods\"\"\"\n",
        "    try:\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            print(\"Error: Could not load image\")\n",
        "            return\n",
        "\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Different Haar Cascade classifiers\n",
        "        classifiers = {\n",
        "            'Default': 'haarcascade_frontalface_default.xml',\n",
        "            'Alt': 'haarcascade_frontalface_alt.xml',\n",
        "            'Alt2': 'haarcascade_frontalface_alt2.xml'\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for name, classifier_file in classifiers.items():\n",
        "            try:\n",
        "                classifier_path = cv2.data.haarcascades + classifier_file\n",
        "                face_cascade = cv2.CascadeClassifier(classifier_path)\n",
        "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "                results[name] = (len(faces), img.copy())\n",
        "\n",
        "                # Draw faces on the copy\n",
        "                for (x, y, w, h) in faces:\n",
        "                    cv2.rectangle(results[name][1], (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "                    cv2.putText(results[name][1], f\"Face\", (x, y-10),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {name} classifier: {e}\")\n",
        "                results[name] = (0, img.copy())\n",
        "\n",
        "        # Display results\n",
        "        fig, axes = plt.subplots(1, len(results), figsize=(15, 5))\n",
        "\n",
        "        if len(results) == 1:\n",
        "            axes = [axes]  # Make it iterable if only one subplot\n",
        "\n",
        "        for idx, (name, (count, result_img)) in enumerate(results.items()):\n",
        "            result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
        "            axes[idx].imshow(result_rgb)\n",
        "            axes[idx].set_title(f'{name}\\n{count} faces detected')\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in comparison: {e}\")\n",
        "\n",
        "# Test different detection methods\n",
        "print(\"Upload an image to compare face detection methods:\")\n",
        "compare_files = files.upload()\n",
        "for filename in compare_files.keys():\n",
        "    compare_face_detection_methods(filename)"
      ],
      "metadata": {
        "id": "sLquoBa1uLDx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Real-time Face Detection System"
      ],
      "metadata": {
        "id": "nnaj4Pg5vVN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceDetectionSystem:\n",
        "    def __init__(self):\n",
        "        self.face_cascade = cv2.CascadeClassifier(\n",
        "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "        )\n",
        "        self.detection_history = []\n",
        "\n",
        "    def detect_faces(self, image_path, draw_landmarks=True):\n",
        "        \"\"\"Detect faces with optional landmark points\"\"\"\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            return None\n",
        "\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))\n",
        "\n",
        "        # Record detection\n",
        "        self.detection_history.append({\n",
        "            'timestamp': time.time(),\n",
        "            'faces_count': len(faces),\n",
        "            'image_path': image_path\n",
        "        })\n",
        "\n",
        "        # Draw detailed annotations\n",
        "        for (x, y, w, h) in faces:\n",
        "            # Main bounding box\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "            # Face center point\n",
        "            center_x, center_y = x + w//2, y + h//2\n",
        "            cv2.circle(img, (center_x, center_y), 3, (255, 0, 0), -1)\n",
        "\n",
        "            # Face label with size\n",
        "            face_size = w * h\n",
        "            label = f\"Face: {w}x{h}px\"\n",
        "            cv2.putText(img, label, (x, y-10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "            # Draw landmark points (simplified)\n",
        "            if draw_landmarks:\n",
        "                landmarks = [\n",
        "                    (x + w//4, y + h//3),    # Left eye\n",
        "                    (x + 3*w//4, y + h//3),  # Right eye\n",
        "                    (x + w//2, y + h//2),    # Nose\n",
        "                    (x + w//3, y + 2*h//3),  # Left mouth\n",
        "                    (x + 2*w//3, y + 2*h//3) # Right mouth\n",
        "                ]\n",
        "\n",
        "                for point in landmarks:\n",
        "                    cv2.circle(img, point, 2, (0, 0, 255), -1)\n",
        "\n",
        "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    def get_statistics(self):\n",
        "        \"\"\"Get detection statistics\"\"\"\n",
        "        if not self.detection_history:\n",
        "            return \"No detections yet\"\n",
        "\n",
        "        total_faces = sum(entry['faces_count'] for entry in self.detection_history)\n",
        "        avg_faces = total_faces / len(self.detection_history)\n",
        "\n",
        "        return f\"\"\"\n",
        "        Detection Statistics:\n",
        "        - Total detections: {len(self.detection_history)}\n",
        "        - Total faces found: {total_faces}\n",
        "        - Average faces per image: {avg_faces:.1f}\n",
        "        \"\"\"\n",
        "\n",
        "# Initialize the system\n",
        "face_system = FaceDetectionSystem()\n",
        "\n",
        "# Test the system\n",
        "print(\"Testing advanced face detection system:\")\n",
        "print(\"Upload images for detailed face detection:\")\n",
        "test_files = files.upload()\n",
        "\n",
        "for filename in test_files.keys():\n",
        "    result = face_system.detect_faces(filename, draw_landmarks=True)\n",
        "    if result is not None:\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(result)\n",
        "        plt.title(f\"Advanced Face Detection: {filename}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Show statistics\n",
        "print(face_system.get_statistics())"
      ],
      "metadata": {
        "id": "EuzOYZnouWYu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Complete Real-time Demo"
      ],
      "metadata": {
        "id": "dZRzOQ8rwCrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_real_time_demo():\n",
        "    \"\"\"Complete real-time face detection demo\"\"\"\n",
        "    print(\"COMPLETE REAL-TIME FACE DETECTION DEMO\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Initialize system\n",
        "    system = FaceDetectionSystem()\n",
        "\n",
        "    # Step 1: Webcam photos\n",
        "    print(\"\\n1. WEBCAM FACE DETECTION\")\n",
        "    print(\"You'll take 2 photos with your webcam\")\n",
        "\n",
        "    for i in range(2):\n",
        "        print(f\"\\n   Preparing photo {i+1}/2...\")\n",
        "        filename = f'demo_photo_{i}.jpg'\n",
        "\n",
        "        try:\n",
        "            photo_path = take_photo(filename)\n",
        "            print(\" Photo captured!\")\n",
        "\n",
        "            # Detect faces\n",
        "            result = system.detect_faces(photo_path, draw_landmarks=True)\n",
        "\n",
        "            if result is not None:\n",
        "                plt.figure(figsize=(10, 8))\n",
        "                plt.imshow(result)\n",
        "                plt.title(f\"Real-time Detection {i+1}\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"No faces detected\")\n",
        "\n",
        "            if i < 1:\n",
        "                time.sleep(2)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "    # Step 2: Upload additional test images\n",
        "    print(\"\\n2.UPLOAD ADDITIONAL TEST IMAGES\")\n",
        "    print(\"Upload more images for testing (optional)\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        result = system.detect_faces(filename, draw_landmarks=False)\n",
        "        if result is not None:\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            plt.imshow(result)\n",
        "            plt.title(f\"Uploaded Image: {filename}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "    # Step 3: Show final statistics\n",
        "    print(\"\\n3. FINAL STATISTICS\")\n",
        "    print(system.get_statistics())\n",
        "\n",
        "    print(\"\\nDemo completed successfully!\")\n",
        "\n",
        "# Run the complete demo\n",
        "complete_real_time_demo()"
      ],
      "metadata": {
        "id": "HWjpeLEKuisu"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj+LhzkfbsY4+166hcMQCn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}